{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aclafsc",
      "provenance": [],
      "collapsed_sections": [
        "yxbi4_3hvUcL",
        "wWi-rBijDQnP"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chan-w/CSCI5525-Final-Project/blob/main/aclafsc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPsf-xF1Fh5W",
        "outputId": "c900c8eb-fbba-43a9-f2bc-f2471bfbd684"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1XwuEpgbX28",
        "outputId": "88e884d8-284c-499d-dc13-b0cb2d2fab6e"
      },
      "source": [
        "%ls gdrive/MyDrive | grep acla"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34maclafsc\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p23HIOu9F8wz",
        "outputId": "e1a2e7fc-6550-4a63-d9ed-b01b48c34208"
      },
      "source": [
        " %cd /content/gdrive/MyDrive/aclafsc/\n",
        " !ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/aclafsc\n",
            "CloserLookFewShot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZpK7QMfG5Vh",
        "outputId": "45b188c8-a6f1-4c65-b3ed-2166b323fb7d"
      },
      "source": [
        "!git clone https://github.com/wyharveychen/CloserLookFewShot.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CloserLookFewShot' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhGs8l3AJ8yk"
      },
      "source": [
        "# !file CUB_200_2011.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhUXLdjnjrc5"
      },
      "source": [
        "# Set Up\n",
        "This section only needs to be run <b>once</b> per user.\n",
        "## CUB\n",
        "Instead of running ```./download_CUB.sh```, add a link in ```aclafsc/CloserLookFewShot/filelists/CUB``` to https://drive.google.com/file/d/1hbzc_P1FuxMkcabkgn9ZKinBwW683j45/view\n",
        "## mini-ImageNet\n",
        "Similarly, add links in ```aclafsc/CloserLookFewShot/filelists/miniImagenet``` to the files in https://drive.google.com/drive/folders/17a09kkqVivZQFggCw9I_YboJ23tcexNM\n",
        "\n",
        "TODO: fix scripts, which seem to expect a different naming convention for files (?)\n",
        "\n",
        "Maybe these versions work better:\n",
        "- Scripts\n",
        "  - https://github.com/wyharveychen/CloserLookFewShot/issues/37#issuecomment-524598549\n",
        "- Data\n",
        "  - https://drive.google.com/file/d/0B3Irx3uQNoBMQ1FlNXJsZUdYWEE/view\n",
        "  - https://github.com/oscarknagg/few-shot\n",
        "- CSV Files\n",
        "  - https://github.com/twitter-research/meta-learning-lstm/tree/master/data/miniImagenet\n",
        "  - Seems to be same as current version\n",
        "\n",
        "\n",
        "## Omniglot\n",
        "The script works.\n",
        "## EMNIST \n",
        "The script works.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuabz02Fur_Q"
      },
      "source": [
        "## CUB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0WSK_glIpkr",
        "outputId": "1a8ecf7a-713c-4282-969d-0307c79dc469"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/aclafsc/CloserLookFewShot/filelists/CUB/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/aclafsc/CloserLookFewShot/filelists/CUB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq5xGcMxI4vh"
      },
      "source": [
        "# !source ./download_CUB.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QOlx6VAcvSJ",
        "outputId": "cdb0089c-8a6a-493d-e088-57e87f0f95e8"
      },
      "source": [
        "# In aclafsc/CloserLookFewShot/filelists/CUB, add a link to https://drive.google.com/file/d/1hbzc_P1FuxMkcabkgn9ZKinBwW683j45/view\n",
        "# instead of trying to download the file\n",
        "!tar -xvf CUB_200_2011.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: CUB_200_2011.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWw8Ib5wdxTy",
        "outputId": "76980fd9-0dc7-4291-bfd5-8913b7a53851"
      },
      "source": [
        "!python write_CUB_filelist.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'write_CUB_filelist.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcJH23e_hN2J",
        "outputId": "14372ae2-5128-45f2-cbbd-d857cc5cbab2"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/aclafsc/CloserLookFewShot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC-7YHRYfB_5"
      },
      "source": [
        "## miniImageNet\n",
        "\n",
        "The URL for the imagenet data is [dead](https://github.com/BayesWatch/deep-kernel-transfer/issues/5).\n",
        "\n",
        "We use the tar files given at https://drive.google.com/drive/folders/17a09kkqVivZQFggCw9I_YboJ23tcexNM instead.\n",
        "\n",
        "We could also generate the dataset from https://github.com/yaoyao-liu/mini-imagenet-tools#requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0gas7qkejKn",
        "outputId": "6f2bcee9-e8d0-4a41-e6a4-ebda5ec3031c"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/aclafsc/CloserLookFewShot/filelists/miniImagenet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/aclafsc/CloserLookFewShot/filelists/miniImagenet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKbVSR5wfoLz"
      },
      "source": [
        "# %pip install miniimagenettools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exvmmgZzemXD",
        "outputId": "74edc2bb-9b7f-4081-e395-191ea5232eda"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/twitter/meta-learning-lstm/master/data/miniImagenet/train.csv \n",
        "!wget https://raw.githubusercontent.com/twitter/meta-learning-lstm/master/data/miniImagenet/val.csv \n",
        "!wget https://raw.githubusercontent.com/twitter/meta-learning-lstm/master/data/miniImagenet/test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-03 02:27:46--  https://raw.githubusercontent.com/twitter/meta-learning-lstm/master/data/miniImagenet/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1228815 (1.2M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]   1.17M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-12-03 02:27:47 (20.9 MB/s) - ‘train.csv’ saved [1228815/1228815]\n",
            "\n",
            "--2021-12-03 02:27:47--  https://raw.githubusercontent.com/twitter/meta-learning-lstm/master/data/miniImagenet/val.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 307215 (300K) [text/plain]\n",
            "Saving to: ‘val.csv’\n",
            "\n",
            "val.csv             100%[===================>] 300.01K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-03 02:27:47 (6.94 MB/s) - ‘val.csv’ saved [307215/307215]\n",
            "\n",
            "--2021-12-03 02:27:47--  https://raw.githubusercontent.com/twitter/meta-learning-lstm/master/data/miniImagenet/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 384015 (375K) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>] 375.01K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-12-03 02:27:47 (10.5 MB/s) - ‘test.csv’ saved [384015/384015]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjyOasODf-mz",
        "outputId": "4ded626a-9d8e-481a-9fc2-44379735a3ac"
      },
      "source": [
        "# The provided python script expects different file names\n",
        "# !mv base.csv train.csv\n",
        "# !mv novel.csv test.csv\n",
        "!tar -xvf val.tar\n",
        "!tar -xvf train.tar\n",
        "!tar -xvf test.tar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: val.tar: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "tar: train.tar: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "tar: test.tar: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAjUHuOjlZ7h",
        "outputId": "e6ed62ad-0b66-4ffa-feff-6149d1855ec6"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/aclafsc/CloserLookFewShot/filelists/miniImagenet\n",
            "base.json\t\t  test.tar   val.tar\n",
            "download_miniImagenet.sh  train.csv  write_cross_filelist.py\n",
            "ILSVRC2015\t\t  train.tar  write_miniImagenet_filelist.py\n",
            "novel.json\t\t  val.csv\n",
            "test.csv\t\t  val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RSlsCe5le65",
        "outputId": "5aa922d1-3ebd-4432-d5b3-506d0c153131"
      },
      "source": [
        "# Build directory structure expected by python scripts\n",
        "!mkdir ILSVRC2015/\n",
        "!mkdir ILSVRC2015/Data\n",
        "!mkdir ILSVRC2015/Data/CLS-LOC/\n",
        "!mv train ILSVRC2015/Data/CLS-LOC/\n",
        "!mv test ILSVRC2015/Data/CLS-LOC/\n",
        "!mv val ILSVRC2015/Data/CLS-LOC/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘ILSVRC2015/’: File exists\n",
            "mkdir: cannot create directory ‘ILSVRC2015/Data’: File exists\n",
            "mkdir: cannot create directory ‘ILSVRC2015/Data/CLS-LOC/’: File exists\n",
            "mv: cannot stat 'train': No such file or directory\n",
            "mv: cannot stat 'test': No such file or directory\n",
            "mv: cannot stat 'val': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miIGHmpSsxrL"
      },
      "source": [
        "### Copied from miniImagenet Python scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_fUyYZkmiQD"
      },
      "source": [
        "# From https://github.com/wyharveychen/CloserLookFewShot/issues/37#issuecomment-524598549\n",
        "import subprocess\n",
        "def write_miniImagenet_filelist():\n",
        "  import numpy as np\n",
        "  from os import listdir\n",
        "  from os.path import isfile, isdir, join\n",
        "  import os\n",
        "  import json\n",
        "  import random\n",
        "  import re\n",
        "\n",
        "  cwd = os.getcwd() \n",
        "  data_path = join(cwd,'ILSVRC2015/Data/CLS-LOC/train') #join(cwd, 'preprocessed') # join(cwd,'ILSVRC2015/Data/CLS-LOC/train')\n",
        "  savedir = './'\n",
        "  dataset_list = ['base', 'val', 'novel']\n",
        "\n",
        "  #if not os.path.exists(savedir):\n",
        "  #    os.makedirs(savedir)\n",
        "\n",
        "  cl = -1\n",
        "  folderlist = [] # to store label??\n",
        "\n",
        "  datasetmap = {'base':'train','val':'val','novel':'test'};\n",
        "  filelists = {'base':{},'val':{},'novel':{} } # label1:[fname1,fname2,...], label2:[fname...], ...\n",
        "  filelists_flat = {'base':[],'val':[],'novel':[] }\n",
        "  labellists_flat = {'base':[],'val':[],'novel':[] }\n",
        "\n",
        "  for dataset in dataset_list:\n",
        "      with open(datasetmap[dataset] + \".csv\", \"r\") as lines: # read train.csv, val.csv, test.csv\n",
        "          for i, line in enumerate(lines):\n",
        "              if i == 0:\n",
        "                  continue\n",
        "              fid, _ , label = re.split(',|\\.', line) # fid here: filename before .jpg\n",
        "              label = label.replace('\\n','')\n",
        "  #             print('fid',fid)\n",
        "  #             print('label',label)\n",
        "              if not label in filelists[dataset]:\n",
        "                  folderlist.append(label)\n",
        "                  filelists[dataset][label] = [] # new label\n",
        "                  query = f'find \"/content/gdrive/My Drive/aclafsc/CloserLookFewShot/filelists/miniImagenet/ILSVRC2015/Data/CLS-LOC/*\" -name \"{label}\"'\n",
        "\n",
        "                  try:\n",
        "                    fnames = listdir( join(data_path, label) ) # preprocessed files names.jpg in this class\n",
        "                  except:\n",
        "                    print(f\"{label} not found in {data_path}, {subprocess.check_output(query, shell=True)}\")\n",
        "                    continue\n",
        "                  for i,fname in enumerate(fnames):\n",
        "  #                 fname_number = [ int(re.split('_|\\.', fname)[1]) for fname in fnames] # BUGFIX\n",
        "                    fname_number = [ int(re.split('_|\\.', fname)[0][1:]) for fname in fnames] # preprocessed files names before.jpg\n",
        "                  sorted_fnames = list(zip( *sorted(  zip(fnames, fname_number), key = lambda f_tuple: f_tuple[1] )))[0] # this class files names.jpg\n",
        "                  \n",
        "  #             fid = int(fid[-5:])-1 # last 5 number of fid\n",
        "  #             print('fid after:',fid,', len of sorted_fnames:',len(sorted_fnames))\n",
        "  #             name = sorted_fnames[fid]\n",
        "              name = fid[-8:] + '.jpg'\n",
        "              fname = join( data_path,label, name ) # file path, BUGFIX: sorted_fnames[fid]\n",
        "              filelists[dataset][label].append(fname)\n",
        "\n",
        "      for key, filelist in filelists[dataset].items():\n",
        "          cl += 1\n",
        "          random.shuffle(filelist)\n",
        "          filelists_flat[dataset] += filelist\n",
        "          labellists_flat[dataset] += np.repeat(cl, len(filelist)).tolist() \n",
        "\n",
        "  for dataset in dataset_list:\n",
        "      fo = open(savedir + dataset + \".json\", \"w\")\n",
        "      fo.write('{\"label_names\": [')\n",
        "      fo.writelines(['\"%s\",' % item  for item in folderlist])\n",
        "      fo.seek(0, os.SEEK_END) \n",
        "      fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "      fo.write('],')\n",
        "\n",
        "      fo.write('\"image_names\": [')\n",
        "      fo.writelines(['\"%s\",' % item  for item in filelists_flat[dataset]])\n",
        "      fo.seek(0, os.SEEK_END) \n",
        "      fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "      fo.write('],')\n",
        "\n",
        "      fo.write('\"image_labels\": [')\n",
        "      fo.writelines(['%d,' % item  for item in labellists_flat[dataset]])\n",
        "      fo.seek(0, os.SEEK_END) \n",
        "      fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "      fo.write(']}')\n",
        "\n",
        "      fo.close()\n",
        "      print(\"%s -OK\" %dataset)\n",
        "\n",
        "  \n",
        "  # import numpy as np\n",
        "  # from os import listdir\n",
        "  # from os.path import isfile, isdir, join\n",
        "  # import os\n",
        "  # import json\n",
        "  # import random\n",
        "  # import re\n",
        "\n",
        "  # cwd = os.getcwd() \n",
        "  # data_path = join(cwd,'ILSVRC2015/Data/CLS-LOC/train')\n",
        "  # savedir = './'\n",
        "  # dataset_list = ['base', 'val', 'novel']\n",
        "\n",
        "  # #if not os.path.exists(savedir):\n",
        "  # #    os.makedirs(savedir)\n",
        "\n",
        "  # cl = -1\n",
        "  # folderlist = []\n",
        "\n",
        "  # datasetmap = {'base':'train','val':'val','novel':'test'};\n",
        "  # filelists = {'base':{},'val':{},'novel':{} }\n",
        "  # filelists_flat = {'base':[],'val':[],'novel':[] }\n",
        "  # labellists_flat = {'base':[],'val':[],'novel':[] }\n",
        "\n",
        "  # for dataset in dataset_list:\n",
        "  #     with open(datasetmap[dataset] + \".csv\", \"r\") as lines:\n",
        "  #         for i, line in enumerate(lines):\n",
        "  #             if i == 0:\n",
        "  #                 continue\n",
        "  #             fid, _ , label = re.split(',|\\.', line)\n",
        "  #             label = label.replace('\\n','')\n",
        "  #             if not label in filelists[dataset]:\n",
        "  #                 folderlist.append(label)\n",
        "  #                 filelists[dataset][label] = []\n",
        "  #                 fnames = listdir( join(data_path, label) )\n",
        "  #                 print(fnames)\n",
        "  #                 fname_number = [ int(re.split('_|\\.|[0]{2}[0]+', fname)[1]) for fname in fnames]\n",
        "  #                 print(fname_number)\n",
        "  #                 sorted_fnames = list(zip( *sorted(  zip(fnames, fname_number), key = lambda f_tuple: f_tuple[1] )))[0]\n",
        "                  \n",
        "  #             fid = int(fid[-5:])-1\n",
        "  #             try:\n",
        "  #               fname = join( data_path,label, sorted_fnames[fid] )\n",
        "  #               filelists[dataset][label].append(fname)\n",
        "\n",
        "  #             except IndexError:\n",
        "  #               print(f'dataset: {dataset}, i: {i}, line: {line}, data_path: {data_path}, label: {label}, sorted_fnames : {sorted_fnames}, fnames_length: {len(sorted_fnames)}, fid: {fid}')\n",
        "  #               # return \n",
        "\n",
        "  #     for key, filelist in filelists[dataset].items():\n",
        "  #         cl += 1\n",
        "  #         random.shuffle(filelist)\n",
        "  #         filelists_flat[dataset] += filelist\n",
        "  #         labellists_flat[dataset] += np.repeat(cl, len(filelist)).tolist() \n",
        "\n",
        "  # for dataset in dataset_list:\n",
        "  #     fo = open(savedir + dataset + \".json\", \"w\")\n",
        "  #     fo.write('{\"label_names\": [')\n",
        "  #     fo.writelines(['\"%s\",' % item  for item in folderlist])\n",
        "  #     fo.seek(0, os.SEEK_END) \n",
        "  #     fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  #     fo.write('],')\n",
        "\n",
        "  #     fo.write('\"image_names\": [')\n",
        "  #     fo.writelines(['\"%s\",' % item  for item in filelists_flat[dataset]])\n",
        "  #     fo.seek(0, os.SEEK_END) \n",
        "  #     fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  #     fo.write('],')\n",
        "\n",
        "  #     fo.write('\"image_labels\": [')\n",
        "  #     fo.writelines(['%d,' % item  for item in labellists_flat[dataset]])\n",
        "  #     fo.seek(0, os.SEEK_END) \n",
        "  #     fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  #     fo.write(']}')\n",
        "\n",
        "  #     fo.close()\n",
        "  #     print(\"%s -OK\" %dataset)\n",
        "\n",
        "def write_cross_filelist():\n",
        "  import numpy as np\n",
        "  from os import listdir\n",
        "  from os.path import isfile, isdir, join\n",
        "  import os\n",
        "  import json\n",
        "  import random\n",
        "  import re\n",
        "\n",
        "  cwd = os.getcwd() \n",
        "  data_path = join(cwd, 'ILSVRC2015/Data/CLS-LOC/train')\n",
        "  savedir = './'\n",
        "  dataset_list = ['base', 'val', 'novel']\n",
        "\n",
        "  #if not os.path.exists(savedir):\n",
        "  #    os.makedirs(savedir)\n",
        "\n",
        "  cl = -1\n",
        "  folderlist = []\n",
        "\n",
        "  datasetmap = {'base':'train','val':'val','novel':'test'};\n",
        "  filelists = {'base':{},'val':{},'novel':{} }\n",
        "  filelists_flat = {'base':[],'val':[],'novel':[] }\n",
        "  labellists_flat = {'base':[],'val':[],'novel':[] }\n",
        "\n",
        "  for dataset in dataset_list:    \n",
        "      with open(datasetmap[dataset] + \".csv\", \"r\") as lines:\n",
        "          for i, line in enumerate(lines):\n",
        "              if i == 0:\n",
        "                  continue\n",
        "              fid, _ , label = re.split(',|\\.', line)\n",
        "              label = label.replace('\\n','')\n",
        "              if not label in filelists[dataset]:\n",
        "                  folderlist.append(label)\n",
        "                  filelists[dataset][label] = []\n",
        "                  try:\n",
        "                    fnames = listdir( join(data_path, label) )\n",
        "                  except FileNotFoundError:\n",
        "                    print(f\"{label} not found in {data_path}\")\n",
        "                    continue\n",
        "                  fname_number = [ int(re.split('_|\\.', fname)[0][1:]) for fname in fnames] # BUGFIXED?\n",
        "                  \n",
        "              name = fid[-8:] + '.jpg'\n",
        "              fname = join(data_path, label, name)\n",
        "              filelists[dataset][label].append(fname)\n",
        "\n",
        "      for key, filelist in filelists[dataset].items():\n",
        "          cl += 1\n",
        "          random.shuffle(filelist)\n",
        "          filelists_flat[dataset] += filelist\n",
        "          labellists_flat[dataset] += np.repeat(cl, len(filelist)).tolist() \n",
        "\n",
        "  #cross setting use base/val/novel together\n",
        "  filelists_flat_all = filelists_flat['base'] + filelists_flat['val'] + filelists_flat['novel']\n",
        "  labellists_flat_all = labellists_flat['base'] + labellists_flat['val'] + labellists_flat['novel']\n",
        "  fo = open(savedir + \"all.json\", \"w\")\n",
        "  fo.write('{\"label_names\": [')\n",
        "  fo.writelines(['\"%s\",' % item  for item in folderlist])\n",
        "  fo.seek(0, os.SEEK_END) \n",
        "  fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  fo.write('],')\n",
        "\n",
        "  fo.write('\"image_names\": [')\n",
        "  fo.writelines(['\"%s\",' % item  for item in filelists_flat_all])\n",
        "  fo.seek(0, os.SEEK_END) \n",
        "  fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  fo.write('],')\n",
        "\n",
        "  fo.write('\"image_labels\": [')\n",
        "  fo.writelines(['%d,' % item  for item in labellists_flat_all])\n",
        "  fo.seek(0, os.SEEK_END) \n",
        "  fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  fo.write(']}')\n",
        "\n",
        "  fo.close()\n",
        "  print(\"all -OK\")\n",
        "\n",
        "  # import numpy as np\n",
        "  # from os import listdir\n",
        "  # from os.path import isfile, isdir, join\n",
        "  # import os\n",
        "  # import json\n",
        "  # import random\n",
        "  # import re\n",
        "\n",
        "  # cwd = os.getcwd() \n",
        "  # data_path = join(cwd,'ILSVRC2015/Data/CLS-LOC/train')\n",
        "  # savedir = './'\n",
        "  # dataset_list = ['base', 'val', 'novel']\n",
        "\n",
        "  # #if not os.path.exists(savedir):\n",
        "  # #    os.makedirs(savedir)\n",
        "\n",
        "  # cl = -1\n",
        "  # folderlist = []\n",
        "\n",
        "  # datasetmap = {'base':'train','val':'val','novel':'test'};\n",
        "  # filelists = {'base':{},'val':{},'novel':{} }\n",
        "  # filelists_flat = {'base':[],'val':[],'novel':[] }\n",
        "  # labellists_flat = {'base':[],'val':[],'novel':[] }\n",
        "\n",
        "  # for dataset in dataset_list:    \n",
        "  #     with open(datasetmap[dataset] + \".csv\", \"r\") as lines:\n",
        "  #         for i, line in enumerate(lines):\n",
        "  #             if i == 0:\n",
        "  #                 continue\n",
        "  #             fid, _ , label = re.split(',|\\.', line)\n",
        "  #             label = label.replace('\\n','')\n",
        "  #             if not label in filelists[dataset]:\n",
        "  #                 folderlist.append(label)\n",
        "  #                 filelists[dataset][label] = []\n",
        "  #                 fnames = listdir( join(data_path, label) )\n",
        "  #                 fname_number = [ int(re.split('_|\\.', fname)[1]) for fname in fnames]\n",
        "  #                 sorted_fnames = list(zip( *sorted(  zip(fnames, fname_number), key = lambda f_tuple: f_tuple[1] )))[0]\n",
        "                  \n",
        "  #             fid = int(fid[-5:])-1\n",
        "  #             print(data_path,label, sorted_fnames, fid)\n",
        "  #             fname = join( data_path,label, sorted_fnames[fid] )\n",
        "  #             filelists[dataset][label].append(fname)\n",
        "\n",
        "  #     for key, filelist in filelists[dataset].items():\n",
        "  #         cl += 1\n",
        "  #         random.shuffle(filelist)\n",
        "  #         filelists_flat[dataset] += filelist\n",
        "  #         labellists_flat[dataset] += np.repeat(cl, len(filelist)).tolist() \n",
        "\n",
        "  # #cross setting use base/val/novel together\n",
        "  # filelists_flat_all = filelists_flat['base'] + filelists_flat['val'] + filelists_flat['novel']\n",
        "  # labellists_flat_all = labellists_flat['base'] + labellists_flat['val'] + labellists_flat['novel']\n",
        "  # fo = open(savedir + \"all.json\", \"w\")\n",
        "  # fo.write('{\"label_names\": [')\n",
        "  # fo.writelines(['\"%s\",' % item  for item in folderlist])\n",
        "  # fo.seek(0, os.SEEK_END) \n",
        "  # fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  # fo.write('],')\n",
        "\n",
        "  # fo.write('\"image_names\": [')\n",
        "  # fo.writelines(['\"%s\",' % item  for item in filelists_flat_all])\n",
        "  # fo.seek(0, os.SEEK_END) \n",
        "  # fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  # fo.write('],')\n",
        "\n",
        "  # fo.write('\"image_labels\": [')\n",
        "  # fo.writelines(['%d,' % item  for item in labellists_flat_all])\n",
        "  # fo.seek(0, os.SEEK_END) \n",
        "  # fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "  # fo.write(']}')\n",
        "\n",
        "  # fo.close()\n",
        "  # print(\"all -OK\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trmYwAR3_xlG",
        "outputId": "08c96209-5a9b-4957-be84-fd8b1dc048c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base.json\t\t  test.tar   val.tar\n",
            "download_miniImagenet.sh  train.csv  write_cross_filelist.py\n",
            "ILSVRC2015\t\t  train.tar  write_miniImagenet_filelist.py\n",
            "novel.json\t\t  val.csv\n",
            "test.csv\t\t  val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Yn8zvwBgiB9v",
        "outputId": "5758d33e-cc04-4316-e604-9559f1154fa4"
      },
      "source": [
        "#!python write_miniImagenet_filelist.py\n",
        "#!python write_cross_filelist.py\n",
        "write_miniImagenet_filelist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a2fd25f41ae1>\u001b[0m in \u001b[0;36mwrite_miniImagenet_filelist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m                   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# preprocessed files names.jpg in this class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/aclafsc/CloserLookFewShot/filelists/miniImagenet/ILSVRC2015/Data/CLS-LOC/train/n01855672'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-914cde900a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!python write_miniImagenet_filelist.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#!python write_cross_filelist.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwrite_miniImagenet_filelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-a2fd25f41ae1>\u001b[0m in \u001b[0;36mwrite_miniImagenet_filelist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# preprocessed files names.jpg in this class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{label} not found in {data_path}, {subprocess.check_output(query, shell=True)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 512\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'find \"/content/gdrive/My Drive/aclafsc/CloserLookFewShot/filelists/miniImagenet/ILSVRC2015/Data/CLS-LOC/*\" -name \"n01855672\"' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynOCoZBIlSh"
      },
      "source": [
        "write_cross_filelist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDxBEOkjr-_s",
        "outputId": "6913229a-7470-4cfa-956d-bbacce722bc6"
      },
      "source": [
        "# The csv expects this in train, but it's in val\n",
        "!find ILSVRC2015/Data/CLS-LOC/* -name \"n01532829\"\n",
        "!find ILSVRC2015/Data/CLS-LOC/* -name \"n01855672\"\n",
        "!find '/content/gdrive/My Drive/aclafsc/CloserLookFewShot/filelists/miniImagenet/ILSVRC2015/Data/CLS-LOC/*' -name \"n01855672\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ILSVRC2015/Data/CLS-LOC/train/n01532829\n",
            "ILSVRC2015/Data/CLS-LOC/val/n01855672\n",
            "find: ‘/content/gdrive/My’: No such file or directory\n",
            "find: ‘Drive/aclafsc/CloserLookFewShot/filelists/miniImagenet/ILSVRC2015/Data/CLS-LOC/*’: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxbi4_3hvUcL"
      },
      "source": [
        "## Omniglot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jEmP2L7vd0T"
      },
      "source": [
        "%cd ../omniglot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yt2xyvrva7g"
      },
      "source": [
        "!source ./download_omniglot.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgnfdKE2BpK8"
      },
      "source": [
        "## EMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4tdBWtSBsU2"
      },
      "source": [
        "%cd ../emnist/\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpqdci2YB4LD"
      },
      "source": [
        "!source ./download_emnist.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWi-rBijDQnP"
      },
      "source": [
        "# Replicating their results\n",
        "\n",
        "We can consider a local runtime one of the CSE Labs machines with GPUs\n",
        "https://research.google.com/colaboratory/local-runtimes.html. The storage quota is too small to download Pytorch though."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMSx1fAgDjVL"
      },
      "source": [
        " %cd /content/drive/MyDrive/aclafsc/CloserLookFewShot/\n",
        " %cd CloserLookFewShot/\n",
        " !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcUtaW60DXIT"
      },
      "source": [
        "!python ./train.py --dataset CUB --model Conv4 --method baseline --train_aug"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}